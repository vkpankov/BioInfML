{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Нейронные сети\n",
    "__Суммарное количество баллов: 10__\n",
    "\n",
    "В этом домашнем задании можно использовать готовые классы библиотек PyTorch, Keras, TensorFlow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:72: UserWarning: h5py is running against HDF5 1.10.2 when it was built against 1.10.3, this may cause problems\n",
      "  '{0}.{1}.{2}'.format(*version.hdf5_built_version_tuple)\n",
      "Using TensorFlow backend.\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import keras\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LoadMnist():\n",
    "    \n",
    "    num_classes = 10\n",
    "\n",
    "    from keras.datasets import mnist\n",
    "    # input image dimensions\n",
    "    img_rows, img_cols = 28, 28\n",
    "\n",
    "    # the data, split between train and test sets\n",
    "    (x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "\n",
    "    x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n",
    "    x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n",
    "    input_shape = (img_rows, img_cols, 1)\n",
    "\n",
    "    x_train = x_train.astype('float32')\n",
    "    x_test = x_test.astype('float32')\n",
    "    x_train /= 255\n",
    "    x_test /= 255\n",
    "\n",
    "    y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "    y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "    \n",
    "    return (x_train, y_train), (x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание 1 (4 балла)\n",
    "\n",
    "Создайте сеть из трех сверточных слоев по 8 сверток 3х3 и двух полносвязных слоев по 64 нейрона. \n",
    "\n",
    "Обучите сеть на датасете mnist с тремя разными функциями активации в слоях (sigmoid, tanh, ReLU)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "def FitMnist(train_data, validation_data, activation = 'relu'):\n",
    "    \n",
    "    model = keras.Sequential([\n",
    "    keras.layers.Conv2D(8, kernel_size = (3,3), input_shape=(28, 28, 1), activation=activation),\n",
    "    keras.layers.Conv2D(8, kernel_size = (3,3), activation=activation),\n",
    "    keras.layers.Flatten(),\n",
    "    keras.layers.Dense(64, activation=activation),\n",
    "    keras.layers.Dense(64, activation=activation),\n",
    "    keras.layers.Dense(num_classes, activation=\"softmax\")])\n",
    "\n",
    "    model.compile(loss=keras.losses.categorical_crossentropy, optimizer=keras.optimizers.Adadelta(), metrics=['accuracy'])\n",
    "    \n",
    "    x_t, y_t = train_data\n",
    "    model.fit(x_t, y_t, validation_data = validation_data)\n",
    "    \n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "60000/60000 [==============================] - 23s 391us/step - loss: 0.1598 - accuracy: 0.9500 - val_loss: 0.0659 - val_accuracy: 0.9796\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.engine.sequential.Sequential at 0x2069b5dc048>"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data, test_data = LoadMnist()\n",
    "FitMnist(train_data, test_data, 'relu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "60000/60000 [==============================] - 28s 470us/step - loss: 0.2047 - accuracy: 0.9399 - val_loss: 0.0999 - val_accuracy: 0.9713\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.engine.sequential.Sequential at 0x2068ac9f248>"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FitMnist(train_data, test_data, 'tanh')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "60000/60000 [==============================] - 26s 439us/step - loss: 2.3082 - accuracy: 0.1045 - val_loss: 2.3075 - val_accuracy: 0.1032\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.engine.sequential.Sequential at 0x2068e4d7648>"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FitMnist(train_data, test_data, 'sigmoid')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание 2 (6 баллов)\n",
    "\n",
    "Достигните точности 87% на test датасете notMNIST.\n",
    "\n",
    "Архитектура сети может быть любая. Можно использовать Data Augmentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "def read_notMNIST(images_dir='notMNIST_small'):\n",
    "    X = []\n",
    "    labels = []\n",
    "    DATA_PATH = images_dir\n",
    "    # for each folder (holding a different set of letters)\n",
    "    for directory in os.listdir(DATA_PATH):\n",
    "        # for each image\n",
    "        for image in os.listdir(DATA_PATH + '/' + directory):\n",
    "            # open image and load array data\n",
    "            try:\n",
    "                file_path = DATA_PATH + '/' + directory + '/' + image\n",
    "                img = Image.open(file_path)\n",
    "                img.load()\n",
    "                img_data = np.asarray(img, dtype=np.int16)\n",
    "                # add image to dataset\n",
    "                X.append(img_data)\n",
    "                # add label to labels\n",
    "                labels.append(directory)\n",
    "            except:\n",
    "                None # do nothing if couldn't load file\n",
    "    N = len(X)\n",
    "    X = np.asarray(X).reshape(N, 28, 28, 1) # add our single channel for processing purposes\n",
    "    labels = keras.utils.to_categorical(list(map(lambda x: ord(x)-ord('A'), labels)), 10) # convert to one-hot\n",
    "    return X, labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "def FitNoMnist(train_data, validation_data, activation = 'relu', batch_size = 32, epochs = 50):\n",
    "    \n",
    "    model = keras.Sequential([\n",
    "    keras.layers.Conv2D(8, kernel_size = (3,3), input_shape=(28, 28, 1), activation=activation),\n",
    "    keras.layers.Conv2D(8, kernel_size = (3,3), activation=activation),\n",
    "    keras.layers.MaxPooling2D(pool_size=(2,2)),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Flatten(),\n",
    "    keras.layers.Dense(64, activation=activation),\n",
    "    keras.layers.Dropout(rate = 0.05),\n",
    "    keras.layers.Dense(256, activation=activation),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Dense(num_classes, activation=\"softmax\")])\n",
    "\n",
    "    model.compile(loss=keras.losses.categorical_crossentropy, optimizer=keras.optimizers.Adadelta(), metrics=['accuracy'])\n",
    "    \n",
    "    datagen = ImageDataGenerator(\n",
    "        rotation_range=15,\n",
    "        zoom_range = 0.15,\n",
    "        width_shift_range=0.15,\n",
    "        height_shift_range=0.15,\n",
    "        horizontal_flip=False,\n",
    "        vertical_flip=False)\n",
    "\n",
    "    xTrain, yTrain = train_data\n",
    "    xTest, yTest = validation_data\n",
    "    \n",
    "    train_gen = datagen.flow(xTrain, yTrain, batch_size=batch_size)\n",
    "    test_gen = datagen.flow(xTest, yTest, batch_size=batch_size)\n",
    "    \n",
    "    model.fit_generator(train_gen, validation_data = test_gen, epochs = epochs,\n",
    "                       steps_per_epoch = X_train.shape[0] // batch_size,\n",
    "                       validation_steps = X_train.shape[0] // batch_size)\n",
    "    \n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "520/520 [==============================] - 11s 21ms/step - loss: 0.8349 - accuracy: 0.7448 - val_loss: 0.7635 - val_accuracy: 0.8197\n",
      "Epoch 2/50\n",
      "520/520 [==============================] - 10s 20ms/step - loss: 0.6071 - accuracy: 0.8186 - val_loss: 0.5667 - val_accuracy: 0.8202\n",
      "Epoch 3/50\n",
      "520/520 [==============================] - 11s 20ms/step - loss: 0.5260 - accuracy: 0.8444 - val_loss: 0.3538 - val_accuracy: 0.8660\n",
      "Epoch 4/50\n",
      "520/520 [==============================] - 11s 20ms/step - loss: 0.4665 - accuracy: 0.8601 - val_loss: 0.2418 - val_accuracy: 0.8752\n",
      "Epoch 5/50\n",
      "520/520 [==============================] - 11s 21ms/step - loss: 0.4433 - accuracy: 0.8678 - val_loss: 0.4694 - val_accuracy: 0.8754\n",
      "Epoch 6/50\n",
      "520/520 [==============================] - 11s 21ms/step - loss: 0.4223 - accuracy: 0.8757 - val_loss: 0.0748 - val_accuracy: 0.8776\n",
      "Epoch 7/50\n",
      "520/520 [==============================] - 11s 21ms/step - loss: 0.4056 - accuracy: 0.8796 - val_loss: 0.1506 - val_accuracy: 0.8840\n",
      "Epoch 8/50\n",
      "520/520 [==============================] - 10s 20ms/step - loss: 0.3952 - accuracy: 0.8829 - val_loss: 0.6200 - val_accuracy: 0.8919\n",
      "Epoch 9/50\n",
      "520/520 [==============================] - 10s 19ms/step - loss: 0.3865 - accuracy: 0.8825 - val_loss: 0.5219 - val_accuracy: 0.8897\n",
      "Epoch 10/50\n",
      "520/520 [==============================] - 10s 19ms/step - loss: 0.3652 - accuracy: 0.8894 - val_loss: 0.6600 - val_accuracy: 0.8927\n",
      "Epoch 11/50\n",
      "520/520 [==============================] - 10s 20ms/step - loss: 0.3672 - accuracy: 0.8902 - val_loss: 0.4701 - val_accuracy: 0.8871\n",
      "Epoch 12/50\n",
      "520/520 [==============================] - 10s 20ms/step - loss: 0.3557 - accuracy: 0.8952 - val_loss: 0.7249 - val_accuracy: 0.9000\n",
      "Epoch 13/50\n",
      "520/520 [==============================] - 10s 19ms/step - loss: 0.3432 - accuracy: 0.8969 - val_loss: 0.3373 - val_accuracy: 0.8941\n",
      "Epoch 14/50\n",
      "520/520 [==============================] - 10s 20ms/step - loss: 0.3381 - accuracy: 0.8993 - val_loss: 0.3009 - val_accuracy: 0.8950\n",
      "Epoch 15/50\n",
      "520/520 [==============================] - 10s 19ms/step - loss: 0.3392 - accuracy: 0.8972 - val_loss: 0.2244 - val_accuracy: 0.9002\n",
      "Epoch 16/50\n",
      "520/520 [==============================] - 10s 19ms/step - loss: 0.3321 - accuracy: 0.8992 - val_loss: 0.5575 - val_accuracy: 0.9004\n",
      "Epoch 17/50\n",
      "520/520 [==============================] - 10s 19ms/step - loss: 0.3257 - accuracy: 0.9015 - val_loss: 0.3691 - val_accuracy: 0.9021\n",
      "Epoch 18/50\n",
      "520/520 [==============================] - 11s 20ms/step - loss: 0.3153 - accuracy: 0.9055 - val_loss: 0.8303 - val_accuracy: 0.9041\n",
      "Epoch 19/50\n",
      "520/520 [==============================] - 12s 23ms/step - loss: 0.3310 - accuracy: 0.9008 - val_loss: 0.7207 - val_accuracy: 0.9064\n",
      "Epoch 20/50\n",
      "520/520 [==============================] - 13s 25ms/step - loss: 0.3054 - accuracy: 0.9078 - val_loss: 0.4928 - val_accuracy: 0.9027\n",
      "Epoch 21/50\n",
      "520/520 [==============================] - 11s 21ms/step - loss: 0.3105 - accuracy: 0.9037 - val_loss: 0.7729 - val_accuracy: 0.9057\n",
      "Epoch 22/50\n",
      "520/520 [==============================] - 10s 20ms/step - loss: 0.3100 - accuracy: 0.9073 - val_loss: 0.3227 - val_accuracy: 0.9059\n",
      "Epoch 23/50\n",
      "520/520 [==============================] - 11s 20ms/step - loss: 0.2995 - accuracy: 0.9092 - val_loss: 0.3434 - val_accuracy: 0.9067\n",
      "Epoch 24/50\n",
      "520/520 [==============================] - 10s 20ms/step - loss: 0.3046 - accuracy: 0.9087 - val_loss: 0.1752 - val_accuracy: 0.9083\n",
      "Epoch 25/50\n",
      "520/520 [==============================] - 10s 20ms/step - loss: 0.3019 - accuracy: 0.9073 - val_loss: 0.3118 - val_accuracy: 0.9085\n",
      "Epoch 26/50\n",
      "520/520 [==============================] - 12s 23ms/step - loss: 0.2839 - accuracy: 0.9128 - val_loss: 0.0485 - val_accuracy: 0.9117\n",
      "Epoch 27/50\n",
      "520/520 [==============================] - 12s 23ms/step - loss: 0.2974 - accuracy: 0.9079 - val_loss: 0.4418 - val_accuracy: 0.9093\n",
      "Epoch 28/50\n",
      "520/520 [==============================] - 10s 20ms/step - loss: 0.2968 - accuracy: 0.9098 - val_loss: 0.6689 - val_accuracy: 0.9123\n",
      "Epoch 29/50\n",
      "520/520 [==============================] - 11s 20ms/step - loss: 0.2816 - accuracy: 0.9147 - val_loss: 0.6512 - val_accuracy: 0.9075\n",
      "Epoch 30/50\n",
      "520/520 [==============================] - 11s 20ms/step - loss: 0.2894 - accuracy: 0.9119 - val_loss: 0.2916 - val_accuracy: 0.9136\n",
      "Epoch 31/50\n",
      "520/520 [==============================] - 10s 20ms/step - loss: 0.2874 - accuracy: 0.9129 - val_loss: 0.3651 - val_accuracy: 0.9149\n",
      "Epoch 32/50\n",
      "520/520 [==============================] - 11s 21ms/step - loss: 0.2790 - accuracy: 0.9173 - val_loss: 0.4691 - val_accuracy: 0.9168\n",
      "Epoch 33/50\n",
      "520/520 [==============================] - 11s 20ms/step - loss: 0.2796 - accuracy: 0.9142 - val_loss: 0.2332 - val_accuracy: 0.9140\n",
      "Epoch 34/50\n",
      "520/520 [==============================] - 11s 20ms/step - loss: 0.2831 - accuracy: 0.9139 - val_loss: 0.0565 - val_accuracy: 0.9130\n",
      "Epoch 35/50\n",
      "520/520 [==============================] - 11s 21ms/step - loss: 0.2718 - accuracy: 0.9165 - val_loss: 0.1700 - val_accuracy: 0.9158\n",
      "Epoch 36/50\n",
      "520/520 [==============================] - 11s 21ms/step - loss: 0.2861 - accuracy: 0.9134 - val_loss: 0.1733 - val_accuracy: 0.9113\n",
      "Epoch 37/50\n",
      "520/520 [==============================] - 11s 21ms/step - loss: 0.2731 - accuracy: 0.9156 - val_loss: 0.3353 - val_accuracy: 0.9078\n",
      "Epoch 38/50\n",
      "520/520 [==============================] - 11s 21ms/step - loss: 0.2721 - accuracy: 0.9157 - val_loss: 0.3862 - val_accuracy: 0.9153\n",
      "Epoch 39/50\n",
      "520/520 [==============================] - 11s 21ms/step - loss: 0.2778 - accuracy: 0.9153 - val_loss: 0.4543 - val_accuracy: 0.9062\n",
      "Epoch 40/50\n",
      "520/520 [==============================] - 11s 21ms/step - loss: 0.2693 - accuracy: 0.9171 - val_loss: 0.0368 - val_accuracy: 0.9147\n",
      "Epoch 41/50\n",
      "520/520 [==============================] - 11s 21ms/step - loss: 0.2754 - accuracy: 0.9155 - val_loss: 0.0127 - val_accuracy: 0.9166\n",
      "Epoch 42/50\n",
      "520/520 [==============================] - 11s 21ms/step - loss: 0.2703 - accuracy: 0.9182 - val_loss: 0.2711 - val_accuracy: 0.9157\n",
      "Epoch 43/50\n",
      "520/520 [==============================] - 10s 20ms/step - loss: 0.2629 - accuracy: 0.9194 - val_loss: 0.3788 - val_accuracy: 0.9175\n",
      "Epoch 44/50\n",
      "520/520 [==============================] - 10s 20ms/step - loss: 0.2670 - accuracy: 0.9182 - val_loss: 0.4914 - val_accuracy: 0.9130\n",
      "Epoch 45/50\n",
      "520/520 [==============================] - 11s 21ms/step - loss: 0.2687 - accuracy: 0.9182 - val_loss: 0.1181 - val_accuracy: 0.9093\n",
      "Epoch 46/50\n",
      "520/520 [==============================] - 11s 21ms/step - loss: 0.2606 - accuracy: 0.9191 - val_loss: 0.0699 - val_accuracy: 0.9167\n",
      "Epoch 47/50\n",
      "520/520 [==============================] - 11s 21ms/step - loss: 0.2596 - accuracy: 0.9214 - val_loss: 0.7123 - val_accuracy: 0.9159\n",
      "Epoch 48/50\n",
      "520/520 [==============================] - 12s 23ms/step - loss: 0.2660 - accuracy: 0.9193 - val_loss: 0.5906 - val_accuracy: 0.9153\n",
      "Epoch 49/50\n",
      "520/520 [==============================] - 11s 21ms/step - loss: 0.2584 - accuracy: 0.9182 - val_loss: 0.3658 - val_accuracy: 0.9120\n",
      "Epoch 50/50\n",
      "520/520 [==============================] - 11s 22ms/step - loss: 0.2522 - accuracy: 0.9223 - val_loss: 0.1275 - val_accuracy: 0.9186\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.engine.sequential.Sequential at 0x2068ac90f48>"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X, y = read_notMNIST()\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.11)\n",
    "\n",
    "FitNoMnist((X_train, y_train), (X_test, y_test), 'tanh')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
