{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Кластеризация\n",
    "__Суммарное количество баллов: 10__\n",
    "\n",
    "В этом домашнем задании предлагается реализовать три различных метода кластеризации, понять, в каких случаях стоит применять те или иные методы."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KDTree\n",
    "from sklearn.datasets import make_blobs, make_moons, make_swiss_roll\n",
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import copy\n",
    "import cv2\n",
    "from collections import deque"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_clasters(X, labels):\n",
    "    unique_labels = np.unique(labels)\n",
    "    unique_colors = np.random.random((len(unique_labels), 3))\n",
    "    colors = [unique_colors[l] for l in labels]\n",
    "    plt.figure(figsize=(9, 9))\n",
    "    plt.scatter(X[:, 0], X[:, 1], c=colors)\n",
    "    plt.show()\n",
    "\n",
    "def clusters_statistics(flatten_image, cluster_colors, cluster_labels):\n",
    "    fig, axes = plt.subplots(3, 2, figsize=(12, 16))\n",
    "    for remove_color in range(3):\n",
    "        axes_pair = axes[remove_color]\n",
    "        first_color = 0 if remove_color != 0 else 2\n",
    "        second_color = 1 if remove_color != 1 else 2\n",
    "        axes_pair[0].scatter([p[first_color] for p in flatten_image], [p[second_color] for p in flatten_image], c=flatten_image, marker='.')\n",
    "        axes_pair[1].scatter([p[first_color] for p in flatten_image], [p[second_color] for p in flatten_image], c=[cluster_colors[c] for c in cluster_labels], marker='.')\n",
    "        for a in axes_pair:\n",
    "            a.set_xlim(0, 1)\n",
    "            a.set_ylim(0, 1)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Генерируем два синтетических набора данных для кластеризации. Далее будем тестировать наши алгоритмы на них."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_1, true_labels = make_blobs(400, 2, centers=[[0, 0], [-4, 0], [3.5, 3.5], [3.5, -2.0]])\n",
    "visualize_clasters(X_1, true_labels)\n",
    "X_2, true_labels = make_moons(400, noise=0.075)\n",
    "visualize_clasters(X_2, true_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание 1 (2 балла)\n",
    "Первый метод, который предлагается реализовать - метод K средних.\n",
    "\n",
    "#### Описание методов\n",
    "`fit(X, y=None)` ищет и запоминает в `self.centroids` центроиды кластеров для набора данных.\n",
    "`predict(X)` для каждого элемента из `X` возвращает номер кластера, к которому относится данный элемент.\n",
    "\n",
    "#### Инициализация кластеров\n",
    "Есть несколько вариантов инициализации кластеров. Нужно реализовать их все:\n",
    "1. `random` - центроиды кластеров являются случайными точками\n",
    "2. `sample` - центроиды кластеров выбираются случайно из набора данных\n",
    "3. `k-means++` - центроиды кластеров инициализируются при помощи метода K-means++\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KMeans:\n",
    "    def __init__(self, n_clusters, init=\"random\", max_iter=300):\n",
    "        raise NotImplementedError()\n",
    "        \n",
    "    def fit(self, X, y=None):\n",
    "        raise NotImplementedError()\n",
    "    \n",
    "    def predict(self, X):\n",
    "        raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Протестируйте алгоритм на синтетических данных. При необходимости подберите гиперпараметры для достижения лучшего качества кластеризации."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = KMeans(n_clusters=4)\n",
    "kmeans.fit(X_1)\n",
    "labels = kmeans.predict(X_1)\n",
    "visualize_clasters(X_1, labels)\n",
    "\n",
    "kmeans = KMeans(n_clusters=2)\n",
    "kmeans.fit(X_2)\n",
    "labels = kmeans.predict(X_2)\n",
    "visualize_clasters(X_2, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание 2 (4 балла)\n",
    "В отличии от K-means, DBScan не позволяет задать количество кластеров, на которое будут разбиты данные. Руководствуясь геометрической интерпретацией, он позволяет выделять кластеры более сложной формы.\n",
    "\n",
    "#### Описание методов\n",
    "`fit_predict(X, y=None)` для каждого элемента `X` возвращает метку кластера, к которому он относится.\n",
    "\n",
    "#### Возможные метрики\n",
    "* `euclidean`\n",
    "* `manhattan`\n",
    "* `chebyshev`\n",
    "\n",
    "__Для быстрого поиска соседей используйте `sklearn.neighbors.KDTree`__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DBScan:\n",
    "    def __init__(self, eps=0.5, min_samples=5, leaf_size=40, metric=\"euclidean\"):\n",
    "        raise NotImplementedError()\n",
    "        \n",
    "    def fit_predict(self, X, y=None):\n",
    "        raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Протестируйте алгоритм на синтетических данных. При необходимости подберите гиперпараметры для достижения лучшего качества кластеризации."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dbscan = DBScan()\n",
    "labels = dbscan.fit_predict(X_1)\n",
    "visualize_clasters(X_1, labels)\n",
    "\n",
    "dbscan = DBScan()\n",
    "labels = dbscan.fit_predict(X_2)\n",
    "visualize_clasters(X_2, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание 3 (4 балла)\n",
    "Идея AgglomerativeClustering заключается в том, чтобы итеративно объединять кластеры с наименьшим расстоянием между ними. Данный метод обладает высокой вычислительной сложностью, поэтому применим только для относительно небольших наборов данных.\n",
    "\n",
    "#### Описание методов\n",
    "`fit_predict(X, y=None)` для каждого элемента `X` возвращает метку кластера, к которому он относится.\n",
    "\n",
    "#### Linkage-функции\n",
    "__Linkage__ - это способ, которым будет рассчитываться расстояние между кластерами. Предлагается реализовать три варианта такой функции:\n",
    "1. `average` - расстояние рассчитывается как среднее расстояние между всеми парами точек, где одна принадлежит первому кластеру, а другая - второму.\n",
    "2. `single` - расстояние рассчитывается как минимальное из расстояний между всеми парами точек, где одна принадлежит первому кластеру, а другая - второму.\n",
    "2. `complete` - расстояние рассчитывается как максимальное из расстояний между всеми парами точек, где одна принадлежит первому кластеру, а другая - второму."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AgglomertiveClustering:\n",
    "    def __init__(self, n_clusters=16, linkage=\"average\"):\n",
    "        raise NotImplementedError()\n",
    "    \n",
    "    def fit_predict(self, X, y=None):\n",
    "        raise NotImplementedError()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Протестируйте алгоритм на синтетических данных. При необходимости подберите гиперпараметры для достижения лучшего качества кластеризации."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_clustering = AgglomertiveClustering(n_clusters=4)\n",
    "labels = agg_clustering.fit_predict(X_1)\n",
    "visualize_clasters(X_1, labels)\n",
    "\n",
    "agg_clustering = AgglomertiveClustering(n_clusters=2)\n",
    "labels = agg_clustering.fit_predict(X_2)\n",
    "visualize_clasters(X_2, labels)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
